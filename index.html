<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Maxime El Masri">
<meta name="author" content="Jérôme Morio">
<meta name="author" content="Florian Simatos">
<meta name="dcterms.date" content="2023-01-16">
<meta name="keywords" content="Importance sampling, High dimension, Gaussian covariance matrix, Kullback-Leibler divergence, Projection">
<meta name="description" content="This document provides a dimension-reduction strategy in order to improve the performance of importance sampling in high dimension.">

<title>Optimal projection for parametric importance sampling in high dimension</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="content_files/libs/clipboard/clipboard.min.js"></script>
<script src="content_files/libs/quarto-html/quarto.js"></script>
<script src="content_files/libs/quarto-html/popper.min.js"></script>
<script src="content_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="content_files/libs/quarto-html/anchor.min.js"></script>
<link href="content_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="content_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="content_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="content_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="content_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>
    .quarto-title-block .quarto-title-banner {
      color: #FFFFFF;
background: #034E79;
    }
    </style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; Optimal projection for parametric importance sampling in high dimension</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>This document provides a dimension-reduction strategy in order to improve the performance of importance sampling in high dimension.</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        Maxime El Masri <a href="https://orcid.org/0000-0002-9127-4503" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://www.onera.fr/">ONERA/DTIS</a>, <a href="https://www.isae-supaero.fr/">ISAE-SUPAERO</a>, <a href="https://www.univ-toulouse.fr/">Université de Toulouse</a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="https://www.onera.fr/en/staff/jerome-morio?destination=node/981">Jérôme Morio</a> <a href="https://orcid.org/0000-0002-8811-8956" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://www.onera.fr/">ONERA/DTIS</a>, <a href="https://www.univ-toulouse.fr/">Université de Toulouse</a>
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="https://pagespro.isae-supaero.fr/florian-simatos/">Florian Simatos</a> 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  <a href="https://www.isae-supaero.fr/">ISAE-SUPAERO</a>, <a href="https://www.univ-toulouse.fr/">Université de Toulouse</a>
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 16, 2023</p>
      </div>
    </div>
                                    
      
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">Importance sampling, High dimension, Gaussian covariance matrix, Kullback-Leibler divergence, Projection</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <p class="date">draft</p>
                  </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>In this paper we propose a dimension-reduction strategy in order to improve the performance of importance sampling in high dimension. The idea is to estimate variance terms in a small number of suitably chosen directions. We first prove that the optimal directions, i.e., the ones that minimize the Kullback–Leibler divergence with the optimal auxiliary density, are the eigenvectors associated to extreme (small or large) eigenvalues of the optimal covariance matrix. We then perform extensive numerical experiments that show that as dimension increases, these directions give estimations which are very close to optimal. Moreover, we show that the estimation remains accurate even when a simple empirical estimator of the covariance matrix is used to estimate these directions. These theoretical and numerical results open the way for different generalizations, in particular the incorporation of such ideas in adaptive importance sampling schemes.</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-sub:portfolio" id="toc-sec-sub:portfolio" class="nav-link active" data-scroll-target="#sec-sub\:portfolio"><span class="toc-section-number">1</span>  Application: large portfolio losses</a></li>
  <li><a href="#bibliography" id="toc-bibliography" class="nav-link" data-scroll-target="#bibliography">Bibliography</a></li>
  </ul>
</nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



<div class="cell" data-execution_count="1">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="im">as</span> sp</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> CEIS_vMFNM <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, Math, Latex</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="sec-sub:portfolio" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-sub:portfolio"><span class="header-section-number">1</span> Application: large portfolio losses</h2>
<p>The next example is a rare event application in finance, taken from <span class="citation" data-cites="BassambooEtAl_PortfolioCreditRisk_2008">(<a href="#ref-BassambooEtAl_PortfolioCreditRisk_2008" role="doc-biblioref">Bassamboo, Juneja, and Zeevi 2008</a>)</span>, <span class="citation" data-cites="ChanKroese_ImprovedCrossentropyMethod_2012">(<a href="#ref-ChanKroese_ImprovedCrossentropyMethod_2012" role="doc-biblioref">Chan and Kroese 2012</a>})</span>. The unknown integral is <span class="math inline">E=\int_{\mathbb{R}^{n+2}} \phi(\mathbf{x}) f(\mathbf{x}) \textrm{d}\mathbf{x} = \mathbb{P}_f(\varphi(\mathbf{X})\geq 0)</span>, with <span class="math inline">\phi = \mathbb{I}_{\{\varphi \geq 0\}}</span> and <span class="math inline">f</span> is the standard <span class="math inline">n+2</span>-dimensional Gaussian distribution. The function <span class="math inline">\varphi</span> is the portfolio loss function defined as: <span id="eq-portfolio"><span class="math display">
    \varphi(\mathbf{x}) = \underset{j=3}{\overset{n+2}{\sum}} \mathbb{I}_{\{\Psi(x_1, x_2, x_j) \geq 0.5\sqrt{n}\}}-0.25 n,
\tag{1}</span></span> with <span class="math display"> \Psi(x_1, x_2, x_j) = \left( q x_1 + 3 (1-q^2)^{1/2}x_j \right) \left[ F_\Gamma^{-1} \left( F_{\mathcal{N}}({x_2}) \right) \right]^{-1/2}, </span> where <span class="math inline">F_\Gamma</span> and <span class="math inline">F_{\mathcal{N}}</span> are the cumulative distribution functions of <span class="math inline">\text{Gamma}(6,6)</span> and <span class="math inline">\mathcal{N}(0,1)</span> random variables respectively.</p>
<p>The reference value of this probability <span class="math inline">E</span> is reported in <a href="#tbl-portfolio">Table&nbsp;1</a> for dimension <span class="math inline">n=100</span>. The optimal parameters <span class="math inline">\mathbf{m}^*</span> and <span class="math inline">\Sigma^*</span> cannot be computed analytically, but they are accurately estimated by Monte Carlo with a large sample. It turns out that <span class="math inline">\mathbf{m}^*</span> and the first eigenvector <span class="math inline">\mathbf{d}^*_1</span> of <span class="math inline">\Sigma^*</span> are numerically indistinguishable and that Algorithm 2 selects <span class="math inline">k=1</span> projection direction, so that numerically, the choices <span class="math inline">{\widehat{\Sigma}^{\text{}}_\text{opt}}</span> and <span class="math inline">{\widehat{\Sigma}^{\text{}}_\text{mean}}</span> are indistinguishable and gives the same estimation results. Actually, the fact that these two estimators behave similarly does not seem to come from the fact that <span class="math inline">\mathbf{m}^*</span> and <span class="math inline">\mathbf{d}^*</span> are close: this relation can be broken for instance by a simple translation argument, but even then they behave similarly. The KL partial divergence and the spectrum with the associated <span class="math inline">\ell</span>-order are presented respectively in <a href="#fig-inefficiency-portfolio-1">Figure&nbsp;1 (a)</a> and in <a href="#fig-inefficiency-portfolio-2">Figure&nbsp;1 (b)</a>.</p>
<div>
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure 5. Evolution of the partial KL divergence and spectrum of the eigenvalues for the large portfolio loss application</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio(X):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array(sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.25</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio_md(X):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array( sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.3</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio_ld(X):</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array(sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.45</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>DKL<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>DKLp<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>DKLm<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>DKLstar<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">100</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>bigsample<span class="op">=</span><span class="dv">20</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span><span class="dv">5</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>M<span class="op">=</span><span class="dv">300</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>):</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d<span class="op">&lt;=</span><span class="dv">30</span>:            </span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio_ld</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d<span class="op">&gt;</span><span class="dv">70</span>:</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio_md</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    VA<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(d<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(d<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>    X01<span class="op">=</span>VA.rvs(size<span class="op">=</span>bigsample)                           </span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    ind1<span class="op">=</span>(phi(X01)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    X1<span class="op">=</span>X01[ind1,:]                                                               </span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>    X1<span class="op">=</span>X1[:M<span class="op">*</span><span class="dv">10</span>,:]</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Mstar</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>    Mstar<span class="op">=</span>np.mean(X1.T,axis<span class="op">=</span><span class="dv">1</span>)                </span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Sigmastar</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>    X1c<span class="op">=</span>(X1<span class="op">-</span>Mstar).T</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    Sigstar<span class="op">=</span>X1c.dot(X1c.T)<span class="op">/</span>np.shape(X1c)[<span class="dv">1</span>]               </span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>    <span class="co">## g*-sample</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>    VA0<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(d<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(d<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>    X0<span class="op">=</span>VA0.rvs(size<span class="op">=</span>M<span class="op">*</span><span class="dv">1000</span>)</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>    ind<span class="op">=</span>(phi(X0)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X0[ind,:]</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X[:M,:]            <span class="co"># g*-sample of size M</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a>    <span class="co">## estimated mean and covariance</span></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a>    mm<span class="op">=</span>np.mean(X,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>    Xc<span class="op">=</span>(X<span class="op">-</span>mm).T</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span>Xc <span class="op">@</span> Xc.T<span class="op">/</span>np.shape(Xc)[<span class="dv">1</span>]</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>    <span class="co">## projection with the eigenvalues of sigma</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>    Eig<span class="op">=</span>np.linalg.eigh(sigma)</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>    logeig<span class="op">=</span>np.sort(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>])</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>    delta<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        delta[j]<span class="op">=</span><span class="bu">abs</span>(logeig[j]<span class="op">-</span>logeig[j<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span>np.argmax(delta)<span class="op">+</span><span class="dv">1</span>         <span class="co"># biggest gap between the l(lambda_i)</span></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a>    indi<span class="op">=</span>[]</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a>        indi.append(np.where(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>]<span class="op">==</span>logeig[l])[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>    P1<span class="op">=</span>np.array(Eig[<span class="dv">1</span>][:,indi[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T                  <span class="co"># projection matrix</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k):</span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a>        P1<span class="op">=</span>np.concatenate((P1,np.array(Eig[<span class="dv">1</span>][:,indi[l]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>    diagsi<span class="op">=</span>np.diag(Eig[<span class="dv">0</span>][indi])</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>    sig_opt_d<span class="op">=</span>P1.dot((diagsi<span class="op">-</span>np.eye(k))).dot(P1.T)<span class="op">+</span>np.eye(d<span class="op">+</span><span class="dv">2</span>)  </span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>    DKL[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(sigma))<span class="op">+</span>np.<span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(sigma))))</span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a>    DKLp[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(sig_opt_d))<span class="op">+</span>np.<span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(sig_opt_d))))</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>    DKLstar[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(Sigstar))<span class="op">+</span>d<span class="op">+</span><span class="dv">2</span></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a><span class="co">#### plot of partial KL divergence</span></span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKL,<span class="st">'rs'</span>,label<span class="op">=</span><span class="vs">r"$D'(\hat{\Sigma}^*)$"</span>)</span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKLp,<span class="st">'k^'</span>,label<span class="op">=</span><span class="vs">r"$D'(\hat{\Sigma}^*_k)$"</span>)</span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKLstar,<span class="st">'bo'</span>,label<span class="op">=</span><span class="vs">r"$D'(\Sigma^*)$"</span>)</span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Dimension'</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"Partial KL divergence $D'$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tickLabel <span class="kw">in</span> plt.gca().get_xticklabels() <span class="op">+</span> plt.gca().get_yticklabels():</span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a>    tickLabel.set_fontsize(<span class="dv">16</span>)</span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a><span class="co">#### plot of the eigenvalues</span></span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a>Eig1<span class="op">=</span>np.linalg.eigh(sigma)</span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>logeig1<span class="op">=</span>np.log(Eig1[<span class="dv">0</span>])<span class="op">-</span>Eig1[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>Table_eigv<span class="op">=</span>np.zeros((n<span class="op">+</span><span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a>Table_eigv[:,<span class="dv">0</span>]<span class="op">=</span>Eig1[<span class="dv">0</span>]</span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>Table_eigv[:,<span class="dv">1</span>]<span class="op">=-</span>logeig1</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a>Eigst<span class="op">=</span>np.linalg.eigh(Sigstar)</span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a>logeigst<span class="op">=</span>np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a>Table_eigv_st<span class="op">=</span>np.zeros((n<span class="op">+</span><span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a>Table_eigv_st[:,<span class="dv">0</span>]<span class="op">=</span>Eigst[<span class="dv">0</span>]</span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a>Table_eigv_st[:,<span class="dv">1</span>]<span class="op">=-</span>logeigst</span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"Eigenvalues $\lambda_i$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\ell(\lambda_i)$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tickLabel <span class="kw">in</span> plt.gca().get_xticklabels() <span class="op">+</span> plt.gca().get_yticklabels():</span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a>    tickLabel.set_fontsize(<span class="dv">16</span>)</span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a>plt.plot(Table_eigv[:,<span class="dv">0</span>],Table_eigv[:,<span class="dv">1</span>],<span class="st">'bx'</span>,label<span class="op">=</span><span class="vs">r"Eigenvalues of $\hat{\Sigma}^*$"</span>)</span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>plt.plot(Table_eigv_st[:,<span class="dv">0</span>],Table_eigv_st[:,<span class="dv">1</span>],<span class="st">'rs'</span>,label<span class="op">=</span><span class="vs">r"Eigenvalues of $\Sigma^*$"</span>)</span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-inefficiency-portfolio" class="cell quarto-layout-panel" data-execution_count="2">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-inefficiency-portfolio-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-inefficiency-portfolio-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-inefficiency-portfolio"></p>
<p></p><figcaption class="figure-caption">(a) Evolution of the partial KL divergence as the dimension increases, with the optimal covariance matrix <span class="math inline">\Sigma^*</span> (blue circles), the sample covariance <span class="math inline">\widehat{\Sigma}^*</span> (red squares), and the projected covariance <span class="math inline">\widehat{\Sigma}^*_k</span> (black triangles).</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-inefficiency-portfolio-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="content_files/figure-html/fig-inefficiency-portfolio-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-inefficiency-portfolio"></p>
<p></p><figcaption class="figure-caption">(b) Computation of <span class="math inline">\ell(\lambda_i)</span> for the eigenvalues of <span class="math inline">\Sigma^*</span> (red squares) and <span class="math inline">\widehat{\Sigma}^*</span> (blue crosses) in dimension <span class="math inline">n = 100</span> for the large portfolio losses of <a href="#eq-portfolio">Equation&nbsp;1</a>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: Partial KL divergence and spectrum for the function <span class="math inline">\phi = \mathbb{I}_{\varphi \geq 0}</span> with <span class="math inline">\varphi</span> the function given by <a href="#eq-portfolio">Equation&nbsp;1</a>.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Table 5. Numerical comparison on the large portfolio loss application</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">100</span>         <span class="co"># dimension</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>phi<span class="op">=</span>Portfolio</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>E<span class="op">=</span><span class="fl">1.82</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">3</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mypi(X):                   </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    f0<span class="op">=</span>sp.stats.multivariate_normal.pdf(X,mean<span class="op">=</span>np.zeros(nn),cov<span class="op">=</span>np.eye(nn))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>((phi(X)<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">*</span>f0)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>N<span class="op">=</span><span class="dv">2000</span>   </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>M<span class="op">=</span><span class="dv">500</span>   </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>B<span class="op">=</span><span class="dv">50</span>    <span class="co"># number of runs</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>Eopt<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>EIS<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>Eprj<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>Eprm<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>Eprjst<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>Eprmst<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>Evmfn<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>SI<span class="op">=</span>[]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>SIP<span class="op">=</span>[]</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>SIPst<span class="op">=</span>[]</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>SIM<span class="op">=</span>[]</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>SIMst<span class="op">=</span>[]</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>bigsample<span class="op">=</span><span class="dv">1</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span><span class="dv">6</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>VA<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(n<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(n<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>X01<span class="op">=</span>VA.rvs(size<span class="op">=</span>bigsample)                           </span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>ind1<span class="op">=</span>(phi(X01)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>X1<span class="op">=</span>X01[ind1,:]                                                               </span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="co">#Mstar</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>Mstar<span class="op">=</span>np.mean(X1.T,axis<span class="op">=</span><span class="dv">1</span>)                </span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co">#Sigmastar</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>X1c<span class="op">=</span>(X1<span class="op">-</span>Mstar).T</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>Sigstar<span class="op">=</span>X1c.dot(X1c.T)<span class="op">/</span>np.shape(X1c)[<span class="dv">1</span>]  </span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>Eigst<span class="op">=</span>np.linalg.eigh(Sigstar)                        </span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>logeigst<span class="op">=</span>np.sort(np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>])         </span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>deltast<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeigst)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeigst)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    deltast[i]<span class="op">=</span><span class="bu">abs</span>(logeigst[i]<span class="op">-</span>logeigst[i<span class="op">+</span><span class="dv">1</span>])         </span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="co">## choice of the number of dimension</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>k_st<span class="op">=</span>np.argmax(deltast)<span class="op">+</span><span class="dv">1</span>     </span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>indist<span class="op">=</span>[]</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k_st):</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>    indist.append(np.where(np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>]<span class="op">==</span>logeigst[i])[<span class="dv">0</span>][<span class="dv">0</span>])           </span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>P1st<span class="op">=</span>np.array(Eigst[<span class="dv">1</span>][:,indist[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T                          </span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k_st):</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>    P1st<span class="op">=</span>np.concatenate((P1st,np.array(Eigst[<span class="dv">1</span>][:,indist[i]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)       <span class="co"># matrix of influential directions</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="co">#np.random.seed(0)</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a><span class="co">############################# Estimation of the matrices</span></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>   <span class="co">## g*-sample of size M</span></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>    VA<span class="op">=</span>sp.stats.multivariate_normal(np.zeros(n<span class="op">+</span><span class="dv">2</span>),np.eye(n<span class="op">+</span><span class="dv">2</span>))      </span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>    X0<span class="op">=</span>VA.rvs(size<span class="op">=</span>M<span class="op">*</span><span class="dv">1000</span>)                   </span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    ind<span class="op">=</span>(phi(X0)<span class="op">&gt;</span><span class="dv">0</span>)          </span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X0[ind,:]                             </span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X[:M,:]           </span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>    R<span class="op">=</span>np.sqrt(np.<span class="bu">sum</span>(X<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))   </span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>    Xu<span class="op">=</span>(X.T<span class="op">/</span>R).T                </span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>   <span class="co">## estimated gaussian mean and covariance </span></span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>    mm<span class="op">=</span>np.mean(X,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>    Xc<span class="op">=</span>(X<span class="op">-</span>mm).T</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span>Xc <span class="op">@</span> Xc.T<span class="op">/</span>np.shape(Xc)[<span class="dv">1</span>]  </span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a>    SI.append(sigma)</span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a>   <span class="co">## von Mises Fisher parameters</span></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>    normu<span class="op">=</span>np.sqrt(np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>).dot(np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>).T))</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>    mu<span class="op">=</span>np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>)<span class="op">/</span>normu</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>    mu<span class="op">=</span>np.array(mu,ndmin<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a>    chi<span class="op">=</span><span class="bu">min</span>(normu,<span class="fl">0.95</span>)</span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>    kappa<span class="op">=</span>(chi<span class="op">*</span>n<span class="op">-</span>chi<span class="op">**</span><span class="dv">3</span>)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>chi<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>   <span class="co">## Nakagami parameters</span></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a>    omega<span class="op">=</span>np.mean(R<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>    tau4<span class="op">=</span>np.mean(R<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a>    pp<span class="op">=</span>omega<span class="op">**</span><span class="dv">2</span><span class="op">/</span>(tau4<span class="op">-</span>omega<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a>    Eig<span class="op">=</span>np.linalg.eigh(sigma)                     </span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a>    logeig<span class="op">=</span>np.sort(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>])     </span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a>    delta<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a>        delta[j]<span class="op">=</span><span class="bu">abs</span>(logeig[j]<span class="op">-</span>logeig[j<span class="op">+</span><span class="dv">1</span>])    </span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span>np.argmax(delta)<span class="op">+</span><span class="dv">1</span>         </span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a>    indi<span class="op">=</span>[]</span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a>        indi.append(np.where(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>]<span class="op">==</span>logeig[l])[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a>    P1<span class="op">=</span>np.array(Eig[<span class="dv">1</span>][:,indi[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k):</span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a>        P1<span class="op">=</span>np.concatenate((P1,np.array(Eig[<span class="dv">1</span>][:,indi[l]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)     </span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a>    diagsi<span class="op">=</span>np.diag(Eig[<span class="dv">0</span>][indi])                           </span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true" tabindex="-1"></a>    sig_opt_d<span class="op">=</span>P1.dot((diagsi<span class="op">-</span>np.eye(k))).dot(P1.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true" tabindex="-1"></a>    SIP.append(sig_opt_d)</span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true" tabindex="-1"></a>    diagsist<span class="op">=</span>P1st.T.dot(sigma).dot(P1st)                   </span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true" tabindex="-1"></a>    sig_opt<span class="op">=</span>P1st.dot(diagsist<span class="op">-</span>np.eye(k_st)).dot(P1st.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a>    SIPst.append(sig_opt)</span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a>    Norm_mm<span class="op">=</span>np.linalg.norm(mm)               </span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a>    normalised_mm<span class="op">=</span>np.array(mm,ndmin<span class="op">=</span><span class="dv">2</span>).T<span class="op">/</span>Norm_mm        </span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a>    vhat<span class="op">=</span>normalised_mm.T.dot(sigma).dot(normalised_mm)          </span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a>    sig_mean_d<span class="op">=</span>(vhat<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>normalised_mm.dot(normalised_mm.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>) </span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a>    SIM.append(sig_mean_d)</span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true" tabindex="-1"></a>    Norm_Mstar<span class="op">=</span>np.linalg.norm(Mstar)               </span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true" tabindex="-1"></a>    normalised_Mstar<span class="op">=</span>np.array(Mstar,ndmin<span class="op">=</span><span class="dv">2</span>).T<span class="op">/</span>Norm_Mstar   </span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true" tabindex="-1"></a>    vhatst<span class="op">=</span>normalised_Mstar.T.dot(sigma).dot(normalised_Mstar)      </span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true" tabindex="-1"></a>    sig_mean<span class="op">=</span>(vhatst<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>normalised_Mstar.dot(normalised_Mstar.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>) </span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true" tabindex="-1"></a>    SIMst.append(sig_mean)</span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true" tabindex="-1"></a><span class="co">############################################# Estimation of the integral</span></span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true" tabindex="-1"></a>    Xop<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>Sigstar,size<span class="op">=</span>N)              </span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true" tabindex="-1"></a>    wop<span class="op">=</span>mypi(Xop)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xop,mean<span class="op">=</span>mm, cov<span class="op">=</span>Sigstar)       </span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true" tabindex="-1"></a>    Eopt[i]<span class="op">=</span>np.mean(wop)                                                     </span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-145"><a href="#cb3-145" aria-hidden="true" tabindex="-1"></a>    Xis<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sigma,size<span class="op">=</span>N)</span>
<span id="cb3-146"><a href="#cb3-146" aria-hidden="true" tabindex="-1"></a>    wis<span class="op">=</span>mypi(Xis)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xis,mean<span class="op">=</span>mm, cov<span class="op">=</span>sigma)</span>
<span id="cb3-147"><a href="#cb3-147" aria-hidden="true" tabindex="-1"></a>    EIS[i]<span class="op">=</span>np.mean(wis)</span>
<span id="cb3-148"><a href="#cb3-148" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-149"><a href="#cb3-149" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-150"><a href="#cb3-150" aria-hidden="true" tabindex="-1"></a>    Xpr<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt_d,size<span class="op">=</span>N)</span>
<span id="cb3-151"><a href="#cb3-151" aria-hidden="true" tabindex="-1"></a>    wpr<span class="op">=</span>mypi(Xpr)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpr,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt_d)</span>
<span id="cb3-152"><a href="#cb3-152" aria-hidden="true" tabindex="-1"></a>    Eprj[i]<span class="op">=</span>np.mean(wpr)</span>
<span id="cb3-153"><a href="#cb3-153" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-154"><a href="#cb3-154" aria-hidden="true" tabindex="-1"></a>   <span class="co">###   </span></span>
<span id="cb3-155"><a href="#cb3-155" aria-hidden="true" tabindex="-1"></a>    Xpm<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean_d,size<span class="op">=</span>N)</span>
<span id="cb3-156"><a href="#cb3-156" aria-hidden="true" tabindex="-1"></a>    wpm<span class="op">=</span>mypi(Xpm)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpm,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean_d)</span>
<span id="cb3-157"><a href="#cb3-157" aria-hidden="true" tabindex="-1"></a>    Eprm[i]<span class="op">=</span>np.mean(wpm)</span>
<span id="cb3-158"><a href="#cb3-158" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-159"><a href="#cb3-159" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb3-160"><a href="#cb3-160" aria-hidden="true" tabindex="-1"></a>    Xprst<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt,size<span class="op">=</span>N)</span>
<span id="cb3-161"><a href="#cb3-161" aria-hidden="true" tabindex="-1"></a>    wprst<span class="op">=</span>mypi(Xprst)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xprst,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt)</span>
<span id="cb3-162"><a href="#cb3-162" aria-hidden="true" tabindex="-1"></a>    Eprjst[i]<span class="op">=</span>np.mean(wprst)</span>
<span id="cb3-163"><a href="#cb3-163" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-164"><a href="#cb3-164" aria-hidden="true" tabindex="-1"></a>   <span class="co">###    </span></span>
<span id="cb3-165"><a href="#cb3-165" aria-hidden="true" tabindex="-1"></a>    Xpmst<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean,size<span class="op">=</span>N)</span>
<span id="cb3-166"><a href="#cb3-166" aria-hidden="true" tabindex="-1"></a>    wpmst<span class="op">=</span>mypi(Xpmst)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpmst,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean)</span>
<span id="cb3-167"><a href="#cb3-167" aria-hidden="true" tabindex="-1"></a>    Eprmst[i]<span class="op">=</span>np.mean(wpmst)</span>
<span id="cb3-168"><a href="#cb3-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-169"><a href="#cb3-169" aria-hidden="true" tabindex="-1"></a>   <span class="co">###</span></span>
<span id="cb3-170"><a href="#cb3-170" aria-hidden="true" tabindex="-1"></a>    Xvmfn <span class="op">=</span> vMFNM_sample(mu, kappa, omega, pp, <span class="dv">1</span>, N)</span>
<span id="cb3-171"><a href="#cb3-171" aria-hidden="true" tabindex="-1"></a>    Rvn<span class="op">=</span>np.sqrt(np.<span class="bu">sum</span>(Xvmfn<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb3-172"><a href="#cb3-172" aria-hidden="true" tabindex="-1"></a>    Xvnu<span class="op">=</span>Xvmfn.T<span class="op">/</span>Rvn</span>
<span id="cb3-173"><a href="#cb3-173" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb3-174"><a href="#cb3-174" aria-hidden="true" tabindex="-1"></a>    h_log<span class="op">=</span>vMF_logpdf(Xvnu,mu.T,kappa)<span class="op">+</span>nakagami_logpdf(Rvn,pp,omega)</span>
<span id="cb3-175"><a href="#cb3-175" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.log(n<span class="op">+</span><span class="dv">2</span>) <span class="op">+</span> np.log(np.pi <span class="op">**</span> ((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>)) <span class="op">-</span> sp.special.gammaln((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb3-176"><a href="#cb3-176" aria-hidden="true" tabindex="-1"></a>    f_u <span class="op">=</span> <span class="op">-</span>A       </span>
<span id="cb3-177"><a href="#cb3-177" aria-hidden="true" tabindex="-1"></a>    f_chi <span class="op">=</span> (np.log(<span class="dv">2</span>) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> (n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>) <span class="op">+</span> np.log(Rvn) <span class="op">*</span> ((n<span class="op">+</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> <span class="fl">0.5</span> <span class="op">*</span> Rvn <span class="op">**</span> <span class="dv">2</span> <span class="op">-</span> sp.special.gammaln((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>)) </span>
<span id="cb3-178"><a href="#cb3-178" aria-hidden="true" tabindex="-1"></a>    f_log <span class="op">=</span> f_u <span class="op">+</span> f_chi</span>
<span id="cb3-179"><a href="#cb3-179" aria-hidden="true" tabindex="-1"></a>    W_log <span class="op">=</span> f_log <span class="op">-</span> h_log</span>
<span id="cb3-180"><a href="#cb3-180" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-181"><a href="#cb3-181" aria-hidden="true" tabindex="-1"></a>    wvmfn<span class="op">=</span>(phi(Xvmfn)<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">*</span>np.exp(W_log)          </span>
<span id="cb3-182"><a href="#cb3-182" aria-hidden="true" tabindex="-1"></a>    Evmfn[i]<span class="op">=</span>np.mean(wvmfn)</span>
<span id="cb3-183"><a href="#cb3-183" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-184"><a href="#cb3-184" aria-hidden="true" tabindex="-1"></a><span class="co">### KL divergences    </span></span>
<span id="cb3-185"><a href="#cb3-185" aria-hidden="true" tabindex="-1"></a>dkli<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-186"><a href="#cb3-186" aria-hidden="true" tabindex="-1"></a>dklp<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-187"><a href="#cb3-187" aria-hidden="true" tabindex="-1"></a>dklm<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-188"><a href="#cb3-188" aria-hidden="true" tabindex="-1"></a>dklpst<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-189"><a href="#cb3-189" aria-hidden="true" tabindex="-1"></a>dklmst<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-190"><a href="#cb3-190" aria-hidden="true" tabindex="-1"></a>dklpca<span class="op">=</span>np.zeros(B)</span>
<span id="cb3-191"><a href="#cb3-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-192"><a href="#cb3-192" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb3-193"><a href="#cb3-193" aria-hidden="true" tabindex="-1"></a>    dkli[i]<span class="op">=</span>np.log(np.linalg.det(SI[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SI[i]))))      </span>
<span id="cb3-194"><a href="#cb3-194" aria-hidden="true" tabindex="-1"></a>    dklp[i]<span class="op">=</span>np.log(np.linalg.det(SIP[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIP[i]))))        </span>
<span id="cb3-195"><a href="#cb3-195" aria-hidden="true" tabindex="-1"></a>    dklm[i]<span class="op">=</span>np.log(np.linalg.det(SIM[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIM[i]))))</span>
<span id="cb3-196"><a href="#cb3-196" aria-hidden="true" tabindex="-1"></a>    dklpst[i]<span class="op">=</span>np.log(np.linalg.det(SIPst[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIPst[i]))))</span>
<span id="cb3-197"><a href="#cb3-197" aria-hidden="true" tabindex="-1"></a>    dklmst[i]<span class="op">=</span>np.log(np.linalg.det(SIMst[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIMst[i]))))</span>
<span id="cb3-198"><a href="#cb3-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-199"><a href="#cb3-199" aria-hidden="true" tabindex="-1"></a>Tabresult<span class="op">=</span>np.zeros((<span class="dv">3</span>,<span class="dv">7</span>)) <span class="co"># table of results</span></span>
<span id="cb3-200"><a href="#cb3-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-201"><a href="#cb3-201" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">0</span>]<span class="op">=</span>np.log(np.linalg.det(Sigstar))<span class="op">+</span>n<span class="op">+</span><span class="dv">2</span></span>
<span id="cb3-202"><a href="#cb3-202" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">1</span>]<span class="op">=</span>np.mean(dkli)</span>
<span id="cb3-203"><a href="#cb3-203" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">2</span>]<span class="op">=</span>np.mean(dklpst)</span>
<span id="cb3-204"><a href="#cb3-204" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">3</span>]<span class="op">=</span>np.mean(dklmst)</span>
<span id="cb3-205"><a href="#cb3-205" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">4</span>]<span class="op">=</span>np.mean(dklp)</span>
<span id="cb3-206"><a href="#cb3-206" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">5</span>]<span class="op">=</span>np.mean(dklm)</span>
<span id="cb3-207"><a href="#cb3-207" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">6</span>]<span class="op">=</span><span class="va">None</span></span>
<span id="cb3-208"><a href="#cb3-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-209"><a href="#cb3-209" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">0</span>]<span class="op">=</span>np.mean(Eopt<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-210"><a href="#cb3-210" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">=</span>np.mean(EIS<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-211"><a href="#cb3-211" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">2</span>]<span class="op">=</span>np.mean(Eprjst<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-212"><a href="#cb3-212" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">3</span>]<span class="op">=</span>np.mean(Eprmst<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-213"><a href="#cb3-213" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">4</span>]<span class="op">=</span>np.mean(Eprj<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-214"><a href="#cb3-214" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">5</span>]<span class="op">=</span>np.mean(Eprm<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-215"><a href="#cb3-215" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">6</span>]<span class="op">=</span>np.mean(Evmfn<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-216"><a href="#cb3-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-217"><a href="#cb3-217" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">0</span>]<span class="op">=</span>np.sqrt(np.mean((Eopt<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-218"><a href="#cb3-218" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">=</span>np.sqrt(np.mean((EIS<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-219"><a href="#cb3-219" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">=</span>np.sqrt(np.mean((Eprjst<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-220"><a href="#cb3-220" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">3</span>]<span class="op">=</span>np.sqrt(np.mean((Eprmst<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-221"><a href="#cb3-221" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">4</span>]<span class="op">=</span>np.sqrt(np.mean((Eprj<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-222"><a href="#cb3-222" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">5</span>]<span class="op">=</span>np.sqrt(np.mean((Eprm<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-223"><a href="#cb3-223" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">6</span>]<span class="op">=</span>np.sqrt(np.mean((Evmfn<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb3-224"><a href="#cb3-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-225"><a href="#cb3-225" aria-hidden="true" tabindex="-1"></a>Tabresult<span class="op">=</span>np.<span class="bu">round</span>(Tabresult,<span class="dv">1</span>)</span>
<span id="cb3-226"><a href="#cb3-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-227"><a href="#cb3-227" aria-hidden="true" tabindex="-1"></a>table<span class="op">=</span>[[<span class="st">"D'"</span>,Tabresult[<span class="dv">0</span>,<span class="dv">0</span>],Tabresult[<span class="dv">0</span>,<span class="dv">1</span>],Tabresult[<span class="dv">0</span>,<span class="dv">2</span>],Tabresult[<span class="dv">0</span>,<span class="dv">3</span>],Tabresult[<span class="dv">0</span>,<span class="dv">4</span>],Tabresult[<span class="dv">0</span>,<span class="dv">5</span>],Tabresult[<span class="dv">0</span>,<span class="dv">6</span>]],</span>
<span id="cb3-228"><a href="#cb3-228" aria-hidden="true" tabindex="-1"></a>      [<span class="st">"Relative error (\%)"</span>,Tabresult[<span class="dv">1</span>,<span class="dv">0</span>],Tabresult[<span class="dv">1</span>,<span class="dv">1</span>],Tabresult[<span class="dv">1</span>,<span class="dv">2</span>],Tabresult[<span class="dv">1</span>,<span class="dv">3</span>],Tabresult[<span class="dv">1</span>,<span class="dv">4</span>],Tabresult[<span class="dv">1</span>,<span class="dv">5</span>],Tabresult[<span class="dv">1</span>,<span class="dv">6</span>]],</span>
<span id="cb3-229"><a href="#cb3-229" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"Coefficient of variation (\%)"</span>,Tabresult[<span class="dv">2</span>,<span class="dv">0</span>],Tabresult[<span class="dv">2</span>,<span class="dv">1</span>],Tabresult[<span class="dv">2</span>,<span class="dv">2</span>],Tabresult[<span class="dv">2</span>,<span class="dv">3</span>],Tabresult[<span class="dv">2</span>,<span class="dv">4</span>],Tabresult[<span class="dv">2</span>,<span class="dv">5</span>],Tabresult[<span class="dv">2</span>,<span class="dv">6</span>]]]</span>
<span id="cb3-230"><a href="#cb3-230" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb3-231"><a href="#cb3-231" aria-hidden="true" tabindex="-1"></a>  table, </span>
<span id="cb3-232"><a href="#cb3-232" aria-hidden="true" tabindex="-1"></a>  headers<span class="op">=</span>[<span class="st">""</span>,<span class="st">"$\Sigma^*$"</span>, <span class="st">"$\hat{\Sigma}^*$"</span>, <span class="st">"$\hat{\Sigma}_</span><span class="sc">{opt}</span><span class="st">$"</span>, <span class="st">"$\hat{\Sigma}_</span><span class="sc">{mean}</span><span class="st">$"</span>, <span class="st">"${\hat{\Sigma}^{+d}_</span><span class="sc">{opt}</span><span class="st">}$"</span>, <span class="st">"$\hat{\Sigma}^{+d}_</span><span class="sc">{mean}</span><span class="st">$"</span>, <span class="st">"vMFN"</span>],</span>
<span id="cb3-233"><a href="#cb3-233" aria-hidden="true" tabindex="-1"></a>    tablefmt<span class="op">=</span><span class="st">"pipe"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<div id="tbl-portfolio" class="anchored">
<table class="table table-sm table-striped">
<caption>Table&nbsp;1: Numerical comparison of the estimation of <span class="math inline">E \approx 1.82 \cdot 10^{-3}</span> considering the Gaussian density with the six covariance matrices defined in <strong>?@sec-def_cov</strong> and the vFMN model,<span class="math inline">\phi = \mathbb{I}_{{\varphi \geq 0}}</span> with <span class="math inline">\varphi</span> given by <a href="#eq-portfolio">Equation&nbsp;1</a>.</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 7%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 4%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\Sigma^*</span></th>
<th style="text-align: right;"><span class="math inline">\hat{\Sigma}^*</span></th>
<th style="text-align: right;"><span class="math inline">\hat{\Sigma}_{opt}</span></th>
<th style="text-align: right;"><span class="math inline">\hat{\Sigma}_{mean}</span></th>
<th style="text-align: right;"><span class="math inline">{\hat{\Sigma}^{+d}_{opt}}</span></th>
<th style="text-align: right;"><span class="math inline">\hat{\Sigma}^{+d}_{mean}</span></th>
<th style="text-align: right;">vMFN</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">D’</td>
<td style="text-align: right;">104.3</td>
<td style="text-align: right;">122.6</td>
<td style="text-align: right;">107.5</td>
<td style="text-align: right;">107.6</td>
<td style="text-align: right;">108</td>
<td style="text-align: right;">107.7</td>
<td style="text-align: right;">nan</td>
</tr>
<tr class="even">
<td style="text-align: left;">Relative error (%)</td>
<td style="text-align: right;">-2.6</td>
<td style="text-align: right;">15.1</td>
<td style="text-align: right;">0.4</td>
<td style="text-align: right;">0.1</td>
<td style="text-align: right;">-1.6</td>
<td style="text-align: right;">0.2</td>
<td style="text-align: right;">-1.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Coefficient of variation (%)</td>
<td style="text-align: right;">17.1</td>
<td style="text-align: right;">482.3</td>
<td style="text-align: right;">5.8</td>
<td style="text-align: right;">7.7</td>
<td style="text-align: right;">8.9</td>
<td style="text-align: right;">7.7</td>
<td style="text-align: right;">6.9</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<!-- -->

</section>
<section id="bibliography" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">Bibliography</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-BassambooEtAl_PortfolioCreditRisk_2008" class="csl-entry" role="doc-biblioentry">
Bassamboo, Achal, Sandeep Juneja, and Assaf Zeevi. 2008. <span>“Portfolio <span>Credit Risk</span> with <span>Extremal Dependence</span>: <span>Asymptotic Analysis</span> and <span>Efficient Simulation</span>.”</span> <em>Operations Research</em> 56 (3): 593–606. <a href="https://doi.org/10.1287/opre.1080.0513">https://doi.org/10.1287/opre.1080.0513</a>.
</div>
<div id="ref-ChanKroese_ImprovedCrossentropyMethod_2012" class="csl-entry" role="doc-biblioentry">
Chan, Joshua C. C., and Dirk P. Kroese. 2012. <span>“Improved Cross-Entropy Method for Estimation.”</span> <em>Statistics and Computing</em> 22 (5): 1031–40. <a href="https://doi.org/10.1007/s11222-011-9275-7">https://doi.org/10.1007/s11222-011-9275-7</a>.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb4" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Optimal projection for parametric importance sampling in high dimension</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Maxime El Masri</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: '[ONERA/DTIS](https://www.onera.fr/), [ISAE-SUPAERO](https://www.isae-supaero.fr/), [Université de Toulouse](https://www.univ-toulouse.fr/)'</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-9127-4503</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Jérôme Morio</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">    url: 'https://www.onera.fr/en/staff/jerome-morio?destination=node/981'</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: '[ONERA/DTIS](https://www.onera.fr/), [Université de Toulouse](https://www.univ-toulouse.fr/)'</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-8811-8956</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Florian Simatos</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">    url: 'https://pagespro.isae-supaero.fr/florian-simatos/'</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: '[ISAE-SUPAERO](https://www.isae-supaero.fr/), [Université de Toulouse](https://www.univ-toulouse.fr/)'</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> last-modified</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">  This document provides a dimension-reduction strategy in order to improve the performance of importance sampling in high dimension.</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="an">abstract:</span><span class="co"> |</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">  In this paper we propose a dimension-reduction strategy in order to improve the performance of importance sampling in high dimension. The idea is to estimate variance terms in a small number of suitably chosen directions. We first prove that the optimal directions, i.e., the ones that minimize the Kullback--Leibler divergence with the optimal auxiliary density, are the eigenvectors associated to extreme (small or large) eigenvalues of the optimal covariance matrix. We then perform extensive numerical experiments that show that as dimension increases, these directions give estimations which are very close to optimal. Moreover, we show that the estimation remains accurate even when a simple empirical estimator of the covariance matrix is used to estimate these directions. These theoretical and numerical results open the way for different generalizations, in particular the incorporation of such ideas in adaptive importance sampling schemes.</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co">  - Importance sampling</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">  - High dimension</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">  - Gaussian covariance matrix</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">  - Kullback-Leibler divergence</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">  - Projection</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> jmorio44</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> optimal-projection-IS</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> true</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> false</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf: default</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co">  keep-ipynb: true</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co">  jupytext:</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co">    text_representation:</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co">      extension: .qmd</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="co">      format_name: quarto</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="co">      format_version: '1.0'</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co">      jupytext_version: 1.14.2</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="co">  kernelspec:</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co">    display_name: Python 3 (ipykernel)</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="co">    language: python</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="co">    name: python3</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="im">as</span> sp</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> CEIS_vMFNM <span class="im">import</span> <span class="op">*</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, Math, Latex</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="fu">## Application: large portfolio losses {#sec-sub:portfolio}</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>The next example is a rare event application in finance, taken from <span class="co">[</span><span class="ot">@BassambooEtAl_PortfolioCreditRisk_2008</span><span class="co">]</span>, <span class="co">[</span><span class="ot">@ChanKroese_ImprovedCrossentropyMethod_2012}</span><span class="co">]</span>. </span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>    The unknown integral is $E=\int_{\mathbb{R}^{n+2}} \phi(\mathbf{x}) f(\mathbf{x}) \textrm{d}\mathbf{x} = \mathbb{P}_f(\varphi(\mathbf{X})\geq 0)$, with $\phi = \mathbb{I}_{<span class="sc">\{</span>\varphi \geq 0<span class="sc">\}</span>}$ and $f$ is the standard $n+2$-dimensional Gaussian distribution. The function $\varphi$ is the portfolio loss function defined as:</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    \varphi(\mathbf{x}) = \underset{j=3}{\overset{n+2}{\sum}} \mathbb{I}_{<span class="sc">\{</span>\Psi(x_1, x_2, x_j) \geq 0.5\sqrt{n}<span class="sc">\}</span>}-0.25 n,</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>$$ {#eq-portfolio}</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>    with</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    $$ \Psi(x_1, x_2, x_j) = \left( q x_1 + 3 (1-q^2)^{1/2}x_j \right) \left<span class="co">[</span><span class="ot"> F_\Gamma^{-1} \left( F_{\mathcal{N}}({x_2}) \right) \right</span><span class="co">]</span>^{-1/2}, $$</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>where $F_\Gamma$ and $F_{\mathcal{N}}$ are the cumulative distribution functions of $\text{Gamma}(6,6)$ and $\mathcal{N}(0,1)$ random variables respectively.</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>The reference value of this probability $E$ is reported in @tbl-portfolio for dimension $n=100$. The optimal parameters $\mathbf{m}^*$ and $\Sigma^*$ cannot be computed analytically, but they are accurately estimated by Monte Carlo with a large sample. It turns out that $\mathbf{m}^*$ and the first eigenvector $\mathbf{d}^*_1$ of $\Sigma^*$ are numerically indistinguishable and that Algorithm 2 selects $k=1$ projection direction, so that numerically, the choices ${\widehat{\Sigma}^{\text{}}_\text{opt}}$ and ${\widehat{\Sigma}^{\text{}}_\text{mean}}$ are indistinguishable and gives the same estimation results. Actually, the fact that these two estimators behave similarly does not seem to come from the fact that $\mathbf{m}^*$ and $\mathbf{d}^*$ are close: this relation can be broken for instance by a simple translation argument, but even then they behave similarly. The KL partial divergence and the spectrum with the associated $\ell$-order are presented respectively in @fig-inefficiency-portfolio-1 and in  @fig-inefficiency-portfolio-2.</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-inefficiency-portfolio</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Partial KL divergence and spectrum for the function $\phi = \mathbb{I}_{\varphi \geq 0}$ with $\varphi$ the function given by @eq-portfolio.'</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-subcap:</span></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a><span class="co">#|   - 'Evolution of the partial KL divergence as the dimension increases, with the optimal covariance matrix $\Sigma^*$ (blue circles), the sample covariance $\widehat{\Sigma}^*$ (red squares), and the projected covariance $\widehat{\Sigma}^*_k$ (black triangles).'</span></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="co">#|   - 'Computation of $\ell(\lambda_i)$ for the eigenvalues of $\Sigma^*$ (red squares) and $\widehat{\Sigma}^*$ (blue crosses) in dimension $n = 100$  for the large portfolio losses of @eq-portfolio.'</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span class="co">#| layout-ncol: 2</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure 5. Evolution of the partial KL divergence and spectrum of the eigenvalues for the large portfolio loss application</span></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio(X):</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array(sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.25</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio_md(X):</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array( sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.3</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Portfolio_ld(X):</span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>    N<span class="op">=</span>np.shape(X)[<span class="dv">0</span>]</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>    lamb<span class="op">=</span>np.array(sp.stats.gamma.ppf(sp.stats.norm.cdf(X[:,<span class="dv">0</span>]),<span class="dv">6</span>,scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>),ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>    eta<span class="op">=</span><span class="dv">3</span><span class="op">*</span>X[:,<span class="dv">2</span>:]</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>    ZZ<span class="op">=</span>np.array(X[:,<span class="dv">1</span>],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>    XX<span class="op">=</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">*</span>ZZ<span class="op">+</span>np.sqrt(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span><span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>eta)<span class="op">/</span>np.sqrt(lamb)</span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>    IndX<span class="op">=</span>(XX<span class="op">&gt;</span><span class="fl">0.5</span><span class="op">*</span>np.sqrt(n))<span class="op">*</span><span class="dv">1</span></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>    PF<span class="op">=</span>np.<span class="bu">sum</span>(IndX,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(PF<span class="op">-</span><span class="fl">0.45</span><span class="op">*</span>n<span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>DKL<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>DKLp<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>DKLm<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>DKLstar<span class="op">=</span>np.zeros(<span class="dv">20</span>)</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">100</span></span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>bigsample<span class="op">=</span><span class="dv">20</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span><span class="dv">5</span></span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>M<span class="op">=</span><span class="dv">300</span></span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>):</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d<span class="op">&lt;=</span><span class="dv">30</span>:            </span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio_ld</span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d<span class="op">&gt;</span><span class="dv">70</span>:</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>        phi<span class="op">=</span>Portfolio_md</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>    VA<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(d<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(d<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>    X01<span class="op">=</span>VA.rvs(size<span class="op">=</span>bigsample)                           </span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>    ind1<span class="op">=</span>(phi(X01)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>    X1<span class="op">=</span>X01[ind1,:]                                                               </span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>    X1<span class="op">=</span>X1[:M<span class="op">*</span><span class="dv">10</span>,:]</span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Mstar</span></span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>    Mstar<span class="op">=</span>np.mean(X1.T,axis<span class="op">=</span><span class="dv">1</span>)                </span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Sigmastar</span></span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>    X1c<span class="op">=</span>(X1<span class="op">-</span>Mstar).T</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>    Sigstar<span class="op">=</span>X1c.dot(X1c.T)<span class="op">/</span>np.shape(X1c)[<span class="dv">1</span>]               </span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a>    <span class="co">## g*-sample</span></span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>    VA0<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(d<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(d<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a>    X0<span class="op">=</span>VA0.rvs(size<span class="op">=</span>M<span class="op">*</span><span class="dv">1000</span>)</span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>    ind<span class="op">=</span>(phi(X0)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X0[ind,:]</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X[:M,:]            <span class="co"># g*-sample of size M</span></span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a>    <span class="co">## estimated mean and covariance</span></span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>    mm<span class="op">=</span>np.mean(X,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a>    Xc<span class="op">=</span>(X<span class="op">-</span>mm).T</span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span>Xc <span class="op">@</span> Xc.T<span class="op">/</span>np.shape(Xc)[<span class="dv">1</span>]</span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a>    <span class="co">## projection with the eigenvalues of sigma</span></span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a>    Eig<span class="op">=</span>np.linalg.eigh(sigma)</span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a>    logeig<span class="op">=</span>np.sort(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>])</span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a>    delta<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>        delta[j]<span class="op">=</span><span class="bu">abs</span>(logeig[j]<span class="op">-</span>logeig[j<span class="op">+</span><span class="dv">1</span>])</span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span>np.argmax(delta)<span class="op">+</span><span class="dv">1</span>         <span class="co"># biggest gap between the l(lambda_i)</span></span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>    indi<span class="op">=</span>[]</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a>        indi.append(np.where(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>]<span class="op">==</span>logeig[l])[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a>    P1<span class="op">=</span>np.array(Eig[<span class="dv">1</span>][:,indi[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T                  <span class="co"># projection matrix</span></span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k):</span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a>        P1<span class="op">=</span>np.concatenate((P1,np.array(Eig[<span class="dv">1</span>][:,indi[l]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>    diagsi<span class="op">=</span>np.diag(Eig[<span class="dv">0</span>][indi])</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>    sig_opt_d<span class="op">=</span>P1.dot((diagsi<span class="op">-</span>np.eye(k))).dot(P1.T)<span class="op">+</span>np.eye(d<span class="op">+</span><span class="dv">2</span>)  </span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a>    DKL[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(sigma))<span class="op">+</span>np.<span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(sigma))))</span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>    DKLp[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(sig_opt_d))<span class="op">+</span>np.<span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(sig_opt_d))))</span>
<span id="cb4-194"><a href="#cb4-194" aria-hidden="true" tabindex="-1"></a>    DKLstar[<span class="bu">int</span>((d<span class="op">-</span><span class="dv">5</span>)<span class="op">/</span><span class="dv">5</span>)]<span class="op">=</span>np.log(np.linalg.det(Sigstar))<span class="op">+</span>d<span class="op">+</span><span class="dv">2</span></span>
<span id="cb4-195"><a href="#cb4-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-196"><a href="#cb4-196" aria-hidden="true" tabindex="-1"></a><span class="co">#### plot of partial KL divergence</span></span>
<span id="cb4-197"><a href="#cb4-197" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKL,<span class="st">'rs'</span>,label<span class="op">=</span><span class="vs">r"$D'(\hat{\Sigma}^*)$"</span>)</span>
<span id="cb4-198"><a href="#cb4-198" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKLp,<span class="st">'k^'</span>,label<span class="op">=</span><span class="vs">r"$D'(\hat{\Sigma}^*_k)$"</span>)</span>
<span id="cb4-199"><a href="#cb4-199" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">5</span>,n<span class="op">+</span><span class="dv">1</span>,<span class="dv">5</span>),DKLstar,<span class="st">'bo'</span>,label<span class="op">=</span><span class="vs">r"$D'(\Sigma^*)$"</span>)</span>
<span id="cb4-200"><a href="#cb4-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-201"><a href="#cb4-201" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb4-202"><a href="#cb4-202" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Dimension'</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-203"><a href="#cb4-203" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"Partial KL divergence $D'$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-204"><a href="#cb4-204" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-205"><a href="#cb4-205" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tickLabel <span class="kw">in</span> plt.gca().get_xticklabels() <span class="op">+</span> plt.gca().get_yticklabels():</span>
<span id="cb4-206"><a href="#cb4-206" aria-hidden="true" tabindex="-1"></a>    tickLabel.set_fontsize(<span class="dv">16</span>)</span>
<span id="cb4-207"><a href="#cb4-207" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-208"><a href="#cb4-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-209"><a href="#cb4-209" aria-hidden="true" tabindex="-1"></a><span class="co">#### plot of the eigenvalues</span></span>
<span id="cb4-210"><a href="#cb4-210" aria-hidden="true" tabindex="-1"></a>Eig1<span class="op">=</span>np.linalg.eigh(sigma)</span>
<span id="cb4-211"><a href="#cb4-211" aria-hidden="true" tabindex="-1"></a>logeig1<span class="op">=</span>np.log(Eig1[<span class="dv">0</span>])<span class="op">-</span>Eig1[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span></span>
<span id="cb4-212"><a href="#cb4-212" aria-hidden="true" tabindex="-1"></a>Table_eigv<span class="op">=</span>np.zeros((n<span class="op">+</span><span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb4-213"><a href="#cb4-213" aria-hidden="true" tabindex="-1"></a>Table_eigv[:,<span class="dv">0</span>]<span class="op">=</span>Eig1[<span class="dv">0</span>]</span>
<span id="cb4-214"><a href="#cb4-214" aria-hidden="true" tabindex="-1"></a>Table_eigv[:,<span class="dv">1</span>]<span class="op">=-</span>logeig1</span>
<span id="cb4-215"><a href="#cb4-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-216"><a href="#cb4-216" aria-hidden="true" tabindex="-1"></a>Eigst<span class="op">=</span>np.linalg.eigh(Sigstar)</span>
<span id="cb4-217"><a href="#cb4-217" aria-hidden="true" tabindex="-1"></a>logeigst<span class="op">=</span>np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>]<span class="op">+</span><span class="dv">1</span></span>
<span id="cb4-218"><a href="#cb4-218" aria-hidden="true" tabindex="-1"></a>Table_eigv_st<span class="op">=</span>np.zeros((n<span class="op">+</span><span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb4-219"><a href="#cb4-219" aria-hidden="true" tabindex="-1"></a>Table_eigv_st[:,<span class="dv">0</span>]<span class="op">=</span>Eigst[<span class="dv">0</span>]</span>
<span id="cb4-220"><a href="#cb4-220" aria-hidden="true" tabindex="-1"></a>Table_eigv_st[:,<span class="dv">1</span>]<span class="op">=-</span>logeigst</span>
<span id="cb4-221"><a href="#cb4-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-222"><a href="#cb4-222" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb4-223"><a href="#cb4-223" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"Eigenvalues $\lambda_i$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-224"><a href="#cb4-224" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\ell(\lambda_i)$"</span>,fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-225"><a href="#cb4-225" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tickLabel <span class="kw">in</span> plt.gca().get_xticklabels() <span class="op">+</span> plt.gca().get_yticklabels():</span>
<span id="cb4-226"><a href="#cb4-226" aria-hidden="true" tabindex="-1"></a>    tickLabel.set_fontsize(<span class="dv">16</span>)</span>
<span id="cb4-227"><a href="#cb4-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-228"><a href="#cb4-228" aria-hidden="true" tabindex="-1"></a>plt.plot(Table_eigv[:,<span class="dv">0</span>],Table_eigv[:,<span class="dv">1</span>],<span class="st">'bx'</span>,label<span class="op">=</span><span class="vs">r"Eigenvalues of $\hat{\Sigma}^*$"</span>)</span>
<span id="cb4-229"><a href="#cb4-229" aria-hidden="true" tabindex="-1"></a>plt.plot(Table_eigv_st[:,<span class="dv">0</span>],Table_eigv_st[:,<span class="dv">1</span>],<span class="st">'rs'</span>,label<span class="op">=</span><span class="vs">r"Eigenvalues of $\Sigma^*$"</span>)</span>
<span id="cb4-230"><a href="#cb4-230" aria-hidden="true" tabindex="-1"></a>plt.legend(fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-231"><a href="#cb4-231" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-232"><a href="#cb4-232" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-233"><a href="#cb4-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-236"><a href="#cb4-236" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-237"><a href="#cb4-237" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-portfolio</span></span>
<span id="cb4-238"><a href="#cb4-238" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Numerical comparison of the estimation of $E \approx 1.82 \cdot 10^{-3}$ considering the Gaussian density with the six covariance matrices defined in @sec-def_cov and the vFMN model,$\phi = \mathbb{I}_{\{\varphi \geq 0\}}$ with $\varphi$ given by @eq-portfolio.'</span></span>
<span id="cb4-239"><a href="#cb4-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-240"><a href="#cb4-240" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb4-241"><a href="#cb4-241" aria-hidden="true" tabindex="-1"></a><span class="co"># Table 5. Numerical comparison on the large portfolio loss application</span></span>
<span id="cb4-242"><a href="#cb4-242" aria-hidden="true" tabindex="-1"></a><span class="co">###############################################################################################################################</span></span>
<span id="cb4-243"><a href="#cb4-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-244"><a href="#cb4-244" aria-hidden="true" tabindex="-1"></a>n<span class="op">=</span><span class="dv">100</span>         <span class="co"># dimension</span></span>
<span id="cb4-245"><a href="#cb4-245" aria-hidden="true" tabindex="-1"></a>phi<span class="op">=</span>Portfolio</span>
<span id="cb4-246"><a href="#cb4-246" aria-hidden="true" tabindex="-1"></a>E<span class="op">=</span><span class="fl">1.82</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">3</span>)</span>
<span id="cb4-247"><a href="#cb4-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-248"><a href="#cb4-248" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mypi(X):                   </span>
<span id="cb4-249"><a href="#cb4-249" aria-hidden="true" tabindex="-1"></a>    nn<span class="op">=</span>np.shape(X)[<span class="dv">1</span>]</span>
<span id="cb4-250"><a href="#cb4-250" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span>nn<span class="op">-</span><span class="dv">2</span></span>
<span id="cb4-251"><a href="#cb4-251" aria-hidden="true" tabindex="-1"></a>    f0<span class="op">=</span>sp.stats.multivariate_normal.pdf(X,mean<span class="op">=</span>np.zeros(nn),cov<span class="op">=</span>np.eye(nn))</span>
<span id="cb4-252"><a href="#cb4-252" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>((phi(X)<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">*</span>f0)</span>
<span id="cb4-253"><a href="#cb4-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-254"><a href="#cb4-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-255"><a href="#cb4-255" aria-hidden="true" tabindex="-1"></a>N<span class="op">=</span><span class="dv">2000</span>   </span>
<span id="cb4-256"><a href="#cb4-256" aria-hidden="true" tabindex="-1"></a>M<span class="op">=</span><span class="dv">500</span>   </span>
<span id="cb4-257"><a href="#cb4-257" aria-hidden="true" tabindex="-1"></a>B<span class="op">=</span><span class="dv">50</span>    <span class="co"># number of runs</span></span>
<span id="cb4-258"><a href="#cb4-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-259"><a href="#cb4-259" aria-hidden="true" tabindex="-1"></a>Eopt<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-260"><a href="#cb4-260" aria-hidden="true" tabindex="-1"></a>EIS<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-261"><a href="#cb4-261" aria-hidden="true" tabindex="-1"></a>Eprj<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-262"><a href="#cb4-262" aria-hidden="true" tabindex="-1"></a>Eprm<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-263"><a href="#cb4-263" aria-hidden="true" tabindex="-1"></a>Eprjst<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-264"><a href="#cb4-264" aria-hidden="true" tabindex="-1"></a>Eprmst<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-265"><a href="#cb4-265" aria-hidden="true" tabindex="-1"></a>Evmfn<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-266"><a href="#cb4-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-267"><a href="#cb4-267" aria-hidden="true" tabindex="-1"></a>SI<span class="op">=</span>[]</span>
<span id="cb4-268"><a href="#cb4-268" aria-hidden="true" tabindex="-1"></a>SIP<span class="op">=</span>[]</span>
<span id="cb4-269"><a href="#cb4-269" aria-hidden="true" tabindex="-1"></a>SIPst<span class="op">=</span>[]</span>
<span id="cb4-270"><a href="#cb4-270" aria-hidden="true" tabindex="-1"></a>SIM<span class="op">=</span>[]</span>
<span id="cb4-271"><a href="#cb4-271" aria-hidden="true" tabindex="-1"></a>SIMst<span class="op">=</span>[]</span>
<span id="cb4-272"><a href="#cb4-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-273"><a href="#cb4-273" aria-hidden="true" tabindex="-1"></a>bigsample<span class="op">=</span><span class="dv">1</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span><span class="dv">6</span></span>
<span id="cb4-274"><a href="#cb4-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-275"><a href="#cb4-275" aria-hidden="true" tabindex="-1"></a>VA<span class="op">=</span>sp.stats.multivariate_normal(mean<span class="op">=</span>np.zeros(n<span class="op">+</span><span class="dv">2</span>),cov<span class="op">=</span>np.eye(n<span class="op">+</span><span class="dv">2</span>))</span>
<span id="cb4-276"><a href="#cb4-276" aria-hidden="true" tabindex="-1"></a>X01<span class="op">=</span>VA.rvs(size<span class="op">=</span>bigsample)                           </span>
<span id="cb4-277"><a href="#cb4-277" aria-hidden="true" tabindex="-1"></a>ind1<span class="op">=</span>(phi(X01)<span class="op">&gt;</span><span class="dv">0</span>)</span>
<span id="cb4-278"><a href="#cb4-278" aria-hidden="true" tabindex="-1"></a>X1<span class="op">=</span>X01[ind1,:]                                                               </span>
<span id="cb4-279"><a href="#cb4-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-280"><a href="#cb4-280" aria-hidden="true" tabindex="-1"></a><span class="co">#Mstar</span></span>
<span id="cb4-281"><a href="#cb4-281" aria-hidden="true" tabindex="-1"></a>Mstar<span class="op">=</span>np.mean(X1.T,axis<span class="op">=</span><span class="dv">1</span>)                </span>
<span id="cb4-282"><a href="#cb4-282" aria-hidden="true" tabindex="-1"></a><span class="co">#Sigmastar</span></span>
<span id="cb4-283"><a href="#cb4-283" aria-hidden="true" tabindex="-1"></a>X1c<span class="op">=</span>(X1<span class="op">-</span>Mstar).T</span>
<span id="cb4-284"><a href="#cb4-284" aria-hidden="true" tabindex="-1"></a>Sigstar<span class="op">=</span>X1c.dot(X1c.T)<span class="op">/</span>np.shape(X1c)[<span class="dv">1</span>]  </span>
<span id="cb4-285"><a href="#cb4-285" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-286"><a href="#cb4-286" aria-hidden="true" tabindex="-1"></a>Eigst<span class="op">=</span>np.linalg.eigh(Sigstar)                        </span>
<span id="cb4-287"><a href="#cb4-287" aria-hidden="true" tabindex="-1"></a>logeigst<span class="op">=</span>np.sort(np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>])         </span>
<span id="cb4-288"><a href="#cb4-288" aria-hidden="true" tabindex="-1"></a>deltast<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeigst)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-289"><a href="#cb4-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-290"><a href="#cb4-290" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeigst)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb4-291"><a href="#cb4-291" aria-hidden="true" tabindex="-1"></a>    deltast[i]<span class="op">=</span><span class="bu">abs</span>(logeigst[i]<span class="op">-</span>logeigst[i<span class="op">+</span><span class="dv">1</span>])         </span>
<span id="cb4-292"><a href="#cb4-292" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-293"><a href="#cb4-293" aria-hidden="true" tabindex="-1"></a><span class="co">## choice of the number of dimension</span></span>
<span id="cb4-294"><a href="#cb4-294" aria-hidden="true" tabindex="-1"></a>k_st<span class="op">=</span>np.argmax(deltast)<span class="op">+</span><span class="dv">1</span>     </span>
<span id="cb4-295"><a href="#cb4-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-296"><a href="#cb4-296" aria-hidden="true" tabindex="-1"></a>indist<span class="op">=</span>[]</span>
<span id="cb4-297"><a href="#cb4-297" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k_st):</span>
<span id="cb4-298"><a href="#cb4-298" aria-hidden="true" tabindex="-1"></a>    indist.append(np.where(np.log(Eigst[<span class="dv">0</span>])<span class="op">-</span>Eigst[<span class="dv">0</span>]<span class="op">==</span>logeigst[i])[<span class="dv">0</span>][<span class="dv">0</span>])           </span>
<span id="cb4-299"><a href="#cb4-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-300"><a href="#cb4-300" aria-hidden="true" tabindex="-1"></a>P1st<span class="op">=</span>np.array(Eigst[<span class="dv">1</span>][:,indist[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T                          </span>
<span id="cb4-301"><a href="#cb4-301" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k_st):</span>
<span id="cb4-302"><a href="#cb4-302" aria-hidden="true" tabindex="-1"></a>    P1st<span class="op">=</span>np.concatenate((P1st,np.array(Eigst[<span class="dv">1</span>][:,indist[i]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)       <span class="co"># matrix of influential directions</span></span>
<span id="cb4-303"><a href="#cb4-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-304"><a href="#cb4-304" aria-hidden="true" tabindex="-1"></a><span class="co">#np.random.seed(0)</span></span>
<span id="cb4-305"><a href="#cb4-305" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb4-306"><a href="#cb4-306" aria-hidden="true" tabindex="-1"></a><span class="co">############################# Estimation of the matrices</span></span>
<span id="cb4-307"><a href="#cb4-307" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-308"><a href="#cb4-308" aria-hidden="true" tabindex="-1"></a>   <span class="co">## g*-sample of size M</span></span>
<span id="cb4-309"><a href="#cb4-309" aria-hidden="true" tabindex="-1"></a>    VA<span class="op">=</span>sp.stats.multivariate_normal(np.zeros(n<span class="op">+</span><span class="dv">2</span>),np.eye(n<span class="op">+</span><span class="dv">2</span>))      </span>
<span id="cb4-310"><a href="#cb4-310" aria-hidden="true" tabindex="-1"></a>    X0<span class="op">=</span>VA.rvs(size<span class="op">=</span>M<span class="op">*</span><span class="dv">1000</span>)                   </span>
<span id="cb4-311"><a href="#cb4-311" aria-hidden="true" tabindex="-1"></a>    ind<span class="op">=</span>(phi(X0)<span class="op">&gt;</span><span class="dv">0</span>)          </span>
<span id="cb4-312"><a href="#cb4-312" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X0[ind,:]                             </span>
<span id="cb4-313"><a href="#cb4-313" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X[:M,:]           </span>
<span id="cb4-314"><a href="#cb4-314" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-315"><a href="#cb4-315" aria-hidden="true" tabindex="-1"></a>    R<span class="op">=</span>np.sqrt(np.<span class="bu">sum</span>(X<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))   </span>
<span id="cb4-316"><a href="#cb4-316" aria-hidden="true" tabindex="-1"></a>    Xu<span class="op">=</span>(X.T<span class="op">/</span>R).T                </span>
<span id="cb4-317"><a href="#cb4-317" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-318"><a href="#cb4-318" aria-hidden="true" tabindex="-1"></a>   <span class="co">## estimated gaussian mean and covariance </span></span>
<span id="cb4-319"><a href="#cb4-319" aria-hidden="true" tabindex="-1"></a>    mm<span class="op">=</span>np.mean(X,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-320"><a href="#cb4-320" aria-hidden="true" tabindex="-1"></a>    Xc<span class="op">=</span>(X<span class="op">-</span>mm).T</span>
<span id="cb4-321"><a href="#cb4-321" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span>Xc <span class="op">@</span> Xc.T<span class="op">/</span>np.shape(Xc)[<span class="dv">1</span>]  </span>
<span id="cb4-322"><a href="#cb4-322" aria-hidden="true" tabindex="-1"></a>    SI.append(sigma)</span>
<span id="cb4-323"><a href="#cb4-323" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-324"><a href="#cb4-324" aria-hidden="true" tabindex="-1"></a>   <span class="co">## von Mises Fisher parameters</span></span>
<span id="cb4-325"><a href="#cb4-325" aria-hidden="true" tabindex="-1"></a>    normu<span class="op">=</span>np.sqrt(np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>).dot(np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>).T))</span>
<span id="cb4-326"><a href="#cb4-326" aria-hidden="true" tabindex="-1"></a>    mu<span class="op">=</span>np.mean(Xu,axis<span class="op">=</span><span class="dv">0</span>)<span class="op">/</span>normu</span>
<span id="cb4-327"><a href="#cb4-327" aria-hidden="true" tabindex="-1"></a>    mu<span class="op">=</span>np.array(mu,ndmin<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-328"><a href="#cb4-328" aria-hidden="true" tabindex="-1"></a>    chi<span class="op">=</span><span class="bu">min</span>(normu,<span class="fl">0.95</span>)</span>
<span id="cb4-329"><a href="#cb4-329" aria-hidden="true" tabindex="-1"></a>    kappa<span class="op">=</span>(chi<span class="op">*</span>n<span class="op">-</span>chi<span class="op">**</span><span class="dv">3</span>)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>chi<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-330"><a href="#cb4-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-331"><a href="#cb4-331" aria-hidden="true" tabindex="-1"></a>   <span class="co">## Nakagami parameters</span></span>
<span id="cb4-332"><a href="#cb4-332" aria-hidden="true" tabindex="-1"></a>    omega<span class="op">=</span>np.mean(R<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-333"><a href="#cb4-333" aria-hidden="true" tabindex="-1"></a>    tau4<span class="op">=</span>np.mean(R<span class="op">**</span><span class="dv">4</span>)</span>
<span id="cb4-334"><a href="#cb4-334" aria-hidden="true" tabindex="-1"></a>    pp<span class="op">=</span>omega<span class="op">**</span><span class="dv">2</span><span class="op">/</span>(tau4<span class="op">-</span>omega<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-335"><a href="#cb4-335" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-336"><a href="#cb4-336" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-337"><a href="#cb4-337" aria-hidden="true" tabindex="-1"></a>    Eig<span class="op">=</span>np.linalg.eigh(sigma)                     </span>
<span id="cb4-338"><a href="#cb4-338" aria-hidden="true" tabindex="-1"></a>    logeig<span class="op">=</span>np.sort(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>])     </span>
<span id="cb4-339"><a href="#cb4-339" aria-hidden="true" tabindex="-1"></a>    delta<span class="op">=</span>np.zeros(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-340"><a href="#cb4-340" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(logeig)<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb4-341"><a href="#cb4-341" aria-hidden="true" tabindex="-1"></a>        delta[j]<span class="op">=</span><span class="bu">abs</span>(logeig[j]<span class="op">-</span>logeig[j<span class="op">+</span><span class="dv">1</span>])    </span>
<span id="cb4-342"><a href="#cb4-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-343"><a href="#cb4-343" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span>np.argmax(delta)<span class="op">+</span><span class="dv">1</span>         </span>
<span id="cb4-344"><a href="#cb4-344" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-345"><a href="#cb4-345" aria-hidden="true" tabindex="-1"></a>    indi<span class="op">=</span>[]</span>
<span id="cb4-346"><a href="#cb4-346" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb4-347"><a href="#cb4-347" aria-hidden="true" tabindex="-1"></a>        indi.append(np.where(np.log(Eig[<span class="dv">0</span>])<span class="op">-</span>Eig[<span class="dv">0</span>]<span class="op">==</span>logeig[l])[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb4-348"><a href="#cb4-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-349"><a href="#cb4-349" aria-hidden="true" tabindex="-1"></a>    P1<span class="op">=</span>np.array(Eig[<span class="dv">1</span>][:,indi[<span class="dv">0</span>]],ndmin<span class="op">=</span><span class="dv">2</span>).T</span>
<span id="cb4-350"><a href="#cb4-350" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,k):</span>
<span id="cb4-351"><a href="#cb4-351" aria-hidden="true" tabindex="-1"></a>        P1<span class="op">=</span>np.concatenate((P1,np.array(Eig[<span class="dv">1</span>][:,indi[l]],ndmin<span class="op">=</span><span class="dv">2</span>).T),axis<span class="op">=</span><span class="dv">1</span>)     </span>
<span id="cb4-352"><a href="#cb4-352" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-353"><a href="#cb4-353" aria-hidden="true" tabindex="-1"></a>    diagsi<span class="op">=</span>np.diag(Eig[<span class="dv">0</span>][indi])                           </span>
<span id="cb4-354"><a href="#cb4-354" aria-hidden="true" tabindex="-1"></a>    sig_opt_d<span class="op">=</span>P1.dot((diagsi<span class="op">-</span>np.eye(k))).dot(P1.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb4-355"><a href="#cb4-355" aria-hidden="true" tabindex="-1"></a>    SIP.append(sig_opt_d)</span>
<span id="cb4-356"><a href="#cb4-356" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-357"><a href="#cb4-357" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-358"><a href="#cb4-358" aria-hidden="true" tabindex="-1"></a>    diagsist<span class="op">=</span>P1st.T.dot(sigma).dot(P1st)                   </span>
<span id="cb4-359"><a href="#cb4-359" aria-hidden="true" tabindex="-1"></a>    sig_opt<span class="op">=</span>P1st.dot(diagsist<span class="op">-</span>np.eye(k_st)).dot(P1st.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>)</span>
<span id="cb4-360"><a href="#cb4-360" aria-hidden="true" tabindex="-1"></a>    SIPst.append(sig_opt)</span>
<span id="cb4-361"><a href="#cb4-361" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-362"><a href="#cb4-362" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-363"><a href="#cb4-363" aria-hidden="true" tabindex="-1"></a>    Norm_mm<span class="op">=</span>np.linalg.norm(mm)               </span>
<span id="cb4-364"><a href="#cb4-364" aria-hidden="true" tabindex="-1"></a>    normalised_mm<span class="op">=</span>np.array(mm,ndmin<span class="op">=</span><span class="dv">2</span>).T<span class="op">/</span>Norm_mm        </span>
<span id="cb4-365"><a href="#cb4-365" aria-hidden="true" tabindex="-1"></a>    vhat<span class="op">=</span>normalised_mm.T.dot(sigma).dot(normalised_mm)          </span>
<span id="cb4-366"><a href="#cb4-366" aria-hidden="true" tabindex="-1"></a>    sig_mean_d<span class="op">=</span>(vhat<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>normalised_mm.dot(normalised_mm.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>) </span>
<span id="cb4-367"><a href="#cb4-367" aria-hidden="true" tabindex="-1"></a>    SIM.append(sig_mean_d)</span>
<span id="cb4-368"><a href="#cb4-368" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-369"><a href="#cb4-369" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-370"><a href="#cb4-370" aria-hidden="true" tabindex="-1"></a>    Norm_Mstar<span class="op">=</span>np.linalg.norm(Mstar)               </span>
<span id="cb4-371"><a href="#cb4-371" aria-hidden="true" tabindex="-1"></a>    normalised_Mstar<span class="op">=</span>np.array(Mstar,ndmin<span class="op">=</span><span class="dv">2</span>).T<span class="op">/</span>Norm_Mstar   </span>
<span id="cb4-372"><a href="#cb4-372" aria-hidden="true" tabindex="-1"></a>    vhatst<span class="op">=</span>normalised_Mstar.T.dot(sigma).dot(normalised_Mstar)      </span>
<span id="cb4-373"><a href="#cb4-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-374"><a href="#cb4-374" aria-hidden="true" tabindex="-1"></a>    sig_mean<span class="op">=</span>(vhatst<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>normalised_Mstar.dot(normalised_Mstar.T)<span class="op">+</span>np.eye(n<span class="op">+</span><span class="dv">2</span>) </span>
<span id="cb4-375"><a href="#cb4-375" aria-hidden="true" tabindex="-1"></a>    SIMst.append(sig_mean)</span>
<span id="cb4-376"><a href="#cb4-376" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-377"><a href="#cb4-377" aria-hidden="true" tabindex="-1"></a><span class="co">############################################# Estimation of the integral</span></span>
<span id="cb4-378"><a href="#cb4-378" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-379"><a href="#cb4-379" aria-hidden="true" tabindex="-1"></a>    Xop<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>Sigstar,size<span class="op">=</span>N)              </span>
<span id="cb4-380"><a href="#cb4-380" aria-hidden="true" tabindex="-1"></a>    wop<span class="op">=</span>mypi(Xop)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xop,mean<span class="op">=</span>mm, cov<span class="op">=</span>Sigstar)       </span>
<span id="cb4-381"><a href="#cb4-381" aria-hidden="true" tabindex="-1"></a>    Eopt[i]<span class="op">=</span>np.mean(wop)                                                     </span>
<span id="cb4-382"><a href="#cb4-382" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-383"><a href="#cb4-383" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-384"><a href="#cb4-384" aria-hidden="true" tabindex="-1"></a>    Xis<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sigma,size<span class="op">=</span>N)</span>
<span id="cb4-385"><a href="#cb4-385" aria-hidden="true" tabindex="-1"></a>    wis<span class="op">=</span>mypi(Xis)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xis,mean<span class="op">=</span>mm, cov<span class="op">=</span>sigma)</span>
<span id="cb4-386"><a href="#cb4-386" aria-hidden="true" tabindex="-1"></a>    EIS[i]<span class="op">=</span>np.mean(wis)</span>
<span id="cb4-387"><a href="#cb4-387" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-388"><a href="#cb4-388" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-389"><a href="#cb4-389" aria-hidden="true" tabindex="-1"></a>    Xpr<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt_d,size<span class="op">=</span>N)</span>
<span id="cb4-390"><a href="#cb4-390" aria-hidden="true" tabindex="-1"></a>    wpr<span class="op">=</span>mypi(Xpr)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpr,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt_d)</span>
<span id="cb4-391"><a href="#cb4-391" aria-hidden="true" tabindex="-1"></a>    Eprj[i]<span class="op">=</span>np.mean(wpr)</span>
<span id="cb4-392"><a href="#cb4-392" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-393"><a href="#cb4-393" aria-hidden="true" tabindex="-1"></a>   <span class="co">###   </span></span>
<span id="cb4-394"><a href="#cb4-394" aria-hidden="true" tabindex="-1"></a>    Xpm<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean_d,size<span class="op">=</span>N)</span>
<span id="cb4-395"><a href="#cb4-395" aria-hidden="true" tabindex="-1"></a>    wpm<span class="op">=</span>mypi(Xpm)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpm,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean_d)</span>
<span id="cb4-396"><a href="#cb4-396" aria-hidden="true" tabindex="-1"></a>    Eprm[i]<span class="op">=</span>np.mean(wpm)</span>
<span id="cb4-397"><a href="#cb4-397" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-398"><a href="#cb4-398" aria-hidden="true" tabindex="-1"></a>   <span class="co">### </span></span>
<span id="cb4-399"><a href="#cb4-399" aria-hidden="true" tabindex="-1"></a>    Xprst<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt,size<span class="op">=</span>N)</span>
<span id="cb4-400"><a href="#cb4-400" aria-hidden="true" tabindex="-1"></a>    wprst<span class="op">=</span>mypi(Xprst)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xprst,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_opt)</span>
<span id="cb4-401"><a href="#cb4-401" aria-hidden="true" tabindex="-1"></a>    Eprjst[i]<span class="op">=</span>np.mean(wprst)</span>
<span id="cb4-402"><a href="#cb4-402" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-403"><a href="#cb4-403" aria-hidden="true" tabindex="-1"></a>   <span class="co">###    </span></span>
<span id="cb4-404"><a href="#cb4-404" aria-hidden="true" tabindex="-1"></a>    Xpmst<span class="op">=</span>sp.stats.multivariate_normal.rvs(mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean,size<span class="op">=</span>N)</span>
<span id="cb4-405"><a href="#cb4-405" aria-hidden="true" tabindex="-1"></a>    wpmst<span class="op">=</span>mypi(Xpmst)<span class="op">/</span>sp.stats.multivariate_normal.pdf(Xpmst,mean<span class="op">=</span>mm, cov<span class="op">=</span>sig_mean)</span>
<span id="cb4-406"><a href="#cb4-406" aria-hidden="true" tabindex="-1"></a>    Eprmst[i]<span class="op">=</span>np.mean(wpmst)</span>
<span id="cb4-407"><a href="#cb4-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-408"><a href="#cb4-408" aria-hidden="true" tabindex="-1"></a>   <span class="co">###</span></span>
<span id="cb4-409"><a href="#cb4-409" aria-hidden="true" tabindex="-1"></a>    Xvmfn <span class="op">=</span> vMFNM_sample(mu, kappa, omega, pp, <span class="dv">1</span>, N)</span>
<span id="cb4-410"><a href="#cb4-410" aria-hidden="true" tabindex="-1"></a>    Rvn<span class="op">=</span>np.sqrt(np.<span class="bu">sum</span>(Xvmfn<span class="op">**</span><span class="dv">2</span>,axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb4-411"><a href="#cb4-411" aria-hidden="true" tabindex="-1"></a>    Xvnu<span class="op">=</span>Xvmfn.T<span class="op">/</span>Rvn</span>
<span id="cb4-412"><a href="#cb4-412" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb4-413"><a href="#cb4-413" aria-hidden="true" tabindex="-1"></a>    h_log<span class="op">=</span>vMF_logpdf(Xvnu,mu.T,kappa)<span class="op">+</span>nakagami_logpdf(Rvn,pp,omega)</span>
<span id="cb4-414"><a href="#cb4-414" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.log(n<span class="op">+</span><span class="dv">2</span>) <span class="op">+</span> np.log(np.pi <span class="op">**</span> ((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>)) <span class="op">-</span> sp.special.gammaln((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb4-415"><a href="#cb4-415" aria-hidden="true" tabindex="-1"></a>    f_u <span class="op">=</span> <span class="op">-</span>A       </span>
<span id="cb4-416"><a href="#cb4-416" aria-hidden="true" tabindex="-1"></a>    f_chi <span class="op">=</span> (np.log(<span class="dv">2</span>) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> (n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>) <span class="op">+</span> np.log(Rvn) <span class="op">*</span> ((n<span class="op">+</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> <span class="fl">0.5</span> <span class="op">*</span> Rvn <span class="op">**</span> <span class="dv">2</span> <span class="op">-</span> sp.special.gammaln((n<span class="op">+</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>)) </span>
<span id="cb4-417"><a href="#cb4-417" aria-hidden="true" tabindex="-1"></a>    f_log <span class="op">=</span> f_u <span class="op">+</span> f_chi</span>
<span id="cb4-418"><a href="#cb4-418" aria-hidden="true" tabindex="-1"></a>    W_log <span class="op">=</span> f_log <span class="op">-</span> h_log</span>
<span id="cb4-419"><a href="#cb4-419" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-420"><a href="#cb4-420" aria-hidden="true" tabindex="-1"></a>    wvmfn<span class="op">=</span>(phi(Xvmfn)<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">*</span>np.exp(W_log)          </span>
<span id="cb4-421"><a href="#cb4-421" aria-hidden="true" tabindex="-1"></a>    Evmfn[i]<span class="op">=</span>np.mean(wvmfn)</span>
<span id="cb4-422"><a href="#cb4-422" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-423"><a href="#cb4-423" aria-hidden="true" tabindex="-1"></a><span class="co">### KL divergences    </span></span>
<span id="cb4-424"><a href="#cb4-424" aria-hidden="true" tabindex="-1"></a>dkli<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-425"><a href="#cb4-425" aria-hidden="true" tabindex="-1"></a>dklp<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-426"><a href="#cb4-426" aria-hidden="true" tabindex="-1"></a>dklm<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-427"><a href="#cb4-427" aria-hidden="true" tabindex="-1"></a>dklpst<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-428"><a href="#cb4-428" aria-hidden="true" tabindex="-1"></a>dklmst<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-429"><a href="#cb4-429" aria-hidden="true" tabindex="-1"></a>dklpca<span class="op">=</span>np.zeros(B)</span>
<span id="cb4-430"><a href="#cb4-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-431"><a href="#cb4-431" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb4-432"><a href="#cb4-432" aria-hidden="true" tabindex="-1"></a>    dkli[i]<span class="op">=</span>np.log(np.linalg.det(SI[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SI[i]))))      </span>
<span id="cb4-433"><a href="#cb4-433" aria-hidden="true" tabindex="-1"></a>    dklp[i]<span class="op">=</span>np.log(np.linalg.det(SIP[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIP[i]))))        </span>
<span id="cb4-434"><a href="#cb4-434" aria-hidden="true" tabindex="-1"></a>    dklm[i]<span class="op">=</span>np.log(np.linalg.det(SIM[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIM[i]))))</span>
<span id="cb4-435"><a href="#cb4-435" aria-hidden="true" tabindex="-1"></a>    dklpst[i]<span class="op">=</span>np.log(np.linalg.det(SIPst[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIPst[i]))))</span>
<span id="cb4-436"><a href="#cb4-436" aria-hidden="true" tabindex="-1"></a>    dklmst[i]<span class="op">=</span>np.log(np.linalg.det(SIMst[i]))<span class="op">+</span><span class="bu">sum</span>(np.diag(Sigstar.dot(np.linalg.inv(SIMst[i]))))</span>
<span id="cb4-437"><a href="#cb4-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-438"><a href="#cb4-438" aria-hidden="true" tabindex="-1"></a>Tabresult<span class="op">=</span>np.zeros((<span class="dv">3</span>,<span class="dv">7</span>)) <span class="co"># table of results</span></span>
<span id="cb4-439"><a href="#cb4-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-440"><a href="#cb4-440" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">0</span>]<span class="op">=</span>np.log(np.linalg.det(Sigstar))<span class="op">+</span>n<span class="op">+</span><span class="dv">2</span></span>
<span id="cb4-441"><a href="#cb4-441" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">1</span>]<span class="op">=</span>np.mean(dkli)</span>
<span id="cb4-442"><a href="#cb4-442" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">2</span>]<span class="op">=</span>np.mean(dklpst)</span>
<span id="cb4-443"><a href="#cb4-443" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">3</span>]<span class="op">=</span>np.mean(dklmst)</span>
<span id="cb4-444"><a href="#cb4-444" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">4</span>]<span class="op">=</span>np.mean(dklp)</span>
<span id="cb4-445"><a href="#cb4-445" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">5</span>]<span class="op">=</span>np.mean(dklm)</span>
<span id="cb4-446"><a href="#cb4-446" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">0</span>,<span class="dv">6</span>]<span class="op">=</span><span class="va">None</span></span>
<span id="cb4-447"><a href="#cb4-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-448"><a href="#cb4-448" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">0</span>]<span class="op">=</span>np.mean(Eopt<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-449"><a href="#cb4-449" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">1</span>]<span class="op">=</span>np.mean(EIS<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-450"><a href="#cb4-450" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">2</span>]<span class="op">=</span>np.mean(Eprjst<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-451"><a href="#cb4-451" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">3</span>]<span class="op">=</span>np.mean(Eprmst<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-452"><a href="#cb4-452" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">4</span>]<span class="op">=</span>np.mean(Eprj<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-453"><a href="#cb4-453" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">5</span>]<span class="op">=</span>np.mean(Eprm<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-454"><a href="#cb4-454" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">1</span>,<span class="dv">6</span>]<span class="op">=</span>np.mean(Evmfn<span class="op">-</span>E)<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-455"><a href="#cb4-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-456"><a href="#cb4-456" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">0</span>]<span class="op">=</span>np.sqrt(np.mean((Eopt<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-457"><a href="#cb4-457" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">1</span>]<span class="op">=</span>np.sqrt(np.mean((EIS<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-458"><a href="#cb4-458" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">2</span>]<span class="op">=</span>np.sqrt(np.mean((Eprjst<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-459"><a href="#cb4-459" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">3</span>]<span class="op">=</span>np.sqrt(np.mean((Eprmst<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-460"><a href="#cb4-460" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">4</span>]<span class="op">=</span>np.sqrt(np.mean((Eprj<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-461"><a href="#cb4-461" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">5</span>]<span class="op">=</span>np.sqrt(np.mean((Eprm<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-462"><a href="#cb4-462" aria-hidden="true" tabindex="-1"></a>Tabresult[<span class="dv">2</span>,<span class="dv">6</span>]<span class="op">=</span>np.sqrt(np.mean((Evmfn<span class="op">-</span>E)<span class="op">**</span><span class="dv">2</span>))<span class="op">/</span>E<span class="op">*</span><span class="dv">100</span></span>
<span id="cb4-463"><a href="#cb4-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-464"><a href="#cb4-464" aria-hidden="true" tabindex="-1"></a>Tabresult<span class="op">=</span>np.<span class="bu">round</span>(Tabresult,<span class="dv">1</span>)</span>
<span id="cb4-465"><a href="#cb4-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-466"><a href="#cb4-466" aria-hidden="true" tabindex="-1"></a>table<span class="op">=</span>[[<span class="st">"D'"</span>,Tabresult[<span class="dv">0</span>,<span class="dv">0</span>],Tabresult[<span class="dv">0</span>,<span class="dv">1</span>],Tabresult[<span class="dv">0</span>,<span class="dv">2</span>],Tabresult[<span class="dv">0</span>,<span class="dv">3</span>],Tabresult[<span class="dv">0</span>,<span class="dv">4</span>],Tabresult[<span class="dv">0</span>,<span class="dv">5</span>],Tabresult[<span class="dv">0</span>,<span class="dv">6</span>]],</span>
<span id="cb4-467"><a href="#cb4-467" aria-hidden="true" tabindex="-1"></a>      [<span class="st">"Relative error (\%)"</span>,Tabresult[<span class="dv">1</span>,<span class="dv">0</span>],Tabresult[<span class="dv">1</span>,<span class="dv">1</span>],Tabresult[<span class="dv">1</span>,<span class="dv">2</span>],Tabresult[<span class="dv">1</span>,<span class="dv">3</span>],Tabresult[<span class="dv">1</span>,<span class="dv">4</span>],Tabresult[<span class="dv">1</span>,<span class="dv">5</span>],Tabresult[<span class="dv">1</span>,<span class="dv">6</span>]],</span>
<span id="cb4-468"><a href="#cb4-468" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"Coefficient of variation (\%)"</span>,Tabresult[<span class="dv">2</span>,<span class="dv">0</span>],Tabresult[<span class="dv">2</span>,<span class="dv">1</span>],Tabresult[<span class="dv">2</span>,<span class="dv">2</span>],Tabresult[<span class="dv">2</span>,<span class="dv">3</span>],Tabresult[<span class="dv">2</span>,<span class="dv">4</span>],Tabresult[<span class="dv">2</span>,<span class="dv">5</span>],Tabresult[<span class="dv">2</span>,<span class="dv">6</span>]]]</span>
<span id="cb4-469"><a href="#cb4-469" aria-hidden="true" tabindex="-1"></a>Markdown(tabulate(</span>
<span id="cb4-470"><a href="#cb4-470" aria-hidden="true" tabindex="-1"></a>  table, </span>
<span id="cb4-471"><a href="#cb4-471" aria-hidden="true" tabindex="-1"></a>  headers<span class="op">=</span>[<span class="st">""</span>,<span class="st">"$\Sigma^*$"</span>, <span class="st">"$\hat{\Sigma}^*$"</span>, <span class="st">"$\hat{\Sigma}_</span><span class="sc">{opt}</span><span class="st">$"</span>, <span class="st">"$\hat{\Sigma}_</span><span class="sc">{mean}</span><span class="st">$"</span>, <span class="st">"${\hat{\Sigma}^{+d}_</span><span class="sc">{opt}</span><span class="st">}$"</span>, <span class="st">"$\hat{\Sigma}^{+d}_</span><span class="sc">{mean}</span><span class="st">$"</span>, <span class="st">"vMFN"</span>],</span>
<span id="cb4-472"><a href="#cb4-472" aria-hidden="true" tabindex="-1"></a>    tablefmt<span class="op">=</span><span class="st">"pipe"</span>))</span>
<span id="cb4-473"><a href="#cb4-473" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>